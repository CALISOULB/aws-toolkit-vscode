/*!
 * Copyright 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 * SPDX-License-Identifier: Apache-2.0
 */

import { getLogger } from '../logger/logger'

/**
 * A polling event. This is generated by a 'ListResources' call and is used to determine if a PollListener
 * should be removed from the event pool, firing callbacks.
 */
export interface PollEvent<Model = any> {
    /** A unique ID for the model. This should be equivalent to the ID assigned by the listener. */
    id: number | string
    /** A 'model' is simply a description of a resource. This does not necessarily need to be fully-descriptive. */
    model: Model
    /** Optionally sets an upper-bound of when the next pollling operation should occur for this specific resource ID. */
    retryAfter?: number
}

/**
 * A listener for resource updates.
 */
export interface PollListener<Model = any> {
    /** A unique ID for the model. */
    id: number | string
    /** A callback that is fired when `isPending` evaluates to false given a new model. */
    update(model: Model): void
    /** Checks whether a new model returned by a poll event is in a STEADY state. */
    isPending(model: Model): boolean
}

interface PoolData<Model> {
    model?: Model
    listener: PollListener<Model>
    collisions: number
    retryAfter: number
}

interface BatchPollerSettings {
    /** The minimum time a new listener should wait until firing poll operations. */
    baseTime: number
    /** Random jitter applied to exponential backoff applications. This is applied per-listener. */
    jitter: number
    /** Flag to enable or disable logging performed by the poller. */
    logging: boolean
}

export type BatchPollerOptions = Partial<BatchPollerSettings> & { name?: string }

/** An asynchronous function that should exhaustively list all resources that could be described by an API call. */
type PollRequester<Model> = () => Promise<PollEvent<Model>[]>

const DEFAULT_SETTINGS: BatchPollerSettings = {
    baseTime: 5000,
    jitter: 0.1,
    logging: false,
}

/**
 * Generic polling class. Allows for batch polling operations and asynchonrous updating resource models.
 * Abstracts the concept of a 'ListResource' operation to get status updates for related resources 'for free',
 * potentially reducing the number of API calls needed for polling operations substantially without sacrificing
 * the responsiveness of singular polling operations.
 *
 * Note that the value of batch polling is founded in the idea that API calls incur a much higher cost on a server
 * than raw bandwidth. That is, 10 API calls that use 10Kb of bandwidth is _much_ cheaper than 100 API calls that use
 * 1Kb.
 */
export class BatchPoller<Model = any> {
    private listenerPool: Map<string, PoolData<Model>> = new Map()
    private pollTimer: NodeJS.Timeout | undefined
    protected timerEnd: number = Number.MAX_VALUE
    protected name: string
    protected settings: BatchPollerSettings

    public constructor(protected readonly listPollEvents: PollRequester<Model>, options: BatchPollerOptions = {}) {
        this.name = options.name ?? '_' + Math.random().toString(36).substr(2, 12)
        this.settings = { ...DEFAULT_SETTINGS, ...options }
    }

    // Note: this a slightly modified form of exponential backoff using a constant 0.5 factor to dampen the slow-down
    private exponentialBackoff(collisions: number): number {
        const jitterOffset = 1 + this.settings.jitter * (Math.random() - 0.5)
        const backoff = 1 + Math.pow(2, Math.max(0, collisions)) * 0.5
        return this.settings.baseTime * jitterOffset * backoff
    }

    private stop(): void {
        if (this.pollTimer !== undefined) {
            clearTimeout(this.pollTimer)
            this.logMessage('stopped')
        }
    }

    private updateElement(element: PoolData<Model>): number {
        if (element.retryAfter < Date.now()) {
            element.retryAfter = Date.now() + this.exponentialBackoff(++element.collisions)
        } else {
            element.retryAfter = Math.max(
                element.retryAfter,
                Date.now() + this.exponentialBackoff(element.collisions - 1)
            )
        }

        return element.retryAfter
    }

    protected logMessage(message: string): void {
        if (this.settings.logging) {
            getLogger().debug(`batch poller (${this.name}): ${message}`)
        }
    }

    /**
     * An event is considered a 'collision' if it occurs some time after a listener's `retryAfter` time.
     * All collisions will have their `retryAfter` time to be updated to the maximum between the returned
     * `retryAfter` time and an exponential backoff application of the previous `retryAfter` time.
     *
     * @returns The number of milliseconds that the poller should wait until performing another poll operation.
     */
    protected updateCollisions(): number {
        let pollDelta = Number.MAX_VALUE
        this.listenerPool.forEach(
            element => (pollDelta = Math.min(pollDelta, this.updateElement(element) - Date.now()))
        )

        return pollDelta
    }

    protected setTimer(delta: number): void {
        if (this.pollTimer !== undefined) {
            clearTimeout(this.pollTimer)
        }
        this.pollTimer = setTimeout(() => this.updatePollEventPool(), delta)
        this.timerEnd = Date.now() + delta
    }

    protected updateTimer(): void {
        if (this.pollTimer === undefined && this.listenerPool.size === 1) {
            this.setTimer(this.settings.baseTime)
            this.logMessage('started')
        } else if (this.listenerPool.size === 0) {
            this.stop()
        } else {
            this.setTimer(this.updateCollisions())
        }
    }

    /**
     * Adds a new listener to events produced by poll requests. Listeners are consumed and callbacks
     * fire when the `isPending` function evaluates to false. That is, callbacks are only fired when
     * the model has reached a TRANSIENT-state. Pending listeners will have their `retryAfter` linearly
     * extrapolated to the maximum between their current `retryAfter` time and the applied exponential
     * backoff time.
     *
     * @param listener @see PollListener
     */
    public addPollListener(listener: PollListener<Model>): void {
        this.listenerPool.set(listener.id.toString(), {
            listener: listener,
            collisions: 0,
            retryAfter: Date.now() + this.settings.baseTime,
        })

        this.updateTimer()
    }

    /**
     * Removes a listener from the batching pool. This regenerates the timer based on the new pool.
     *
     * @param listener A PollListener or the listener's ID to remove.
     */
    public removePollListener(listener: PollListener<Model> | PollListener['id']): void {
        listener =
            typeof listener === 'string' || typeof listener === 'number' ? listener.toString() : listener.id.toString()
        this.listenerPool.delete(listener)

        this.updateTimer()
    }

    protected async updatePollEventPool(): Promise<void> {
        this.logMessage(`refresh ${new Date(Date.now()).toISOString()}`)
        const newPollEvents = await this.listPollEvents()

        newPollEvents.forEach(event => this.processEvent(event))

        this.updateTimer()
    }

    private processEvent(event: PollEvent<Model>): void {
        const element = this.listenerPool.get(event.id.toString())

        if (element === undefined) {
            return
        }

        const listener = element.listener

        if (!listener.isPending(event.model)) {
            if (listener.update !== undefined) {
                this.logMessage(`updated ${event.id}`)
                listener.update(event.model)
            }

            this.listenerPool.delete(listener.id.toString())
        } else {
            element.retryAfter = Math.max(element.retryAfter, event.retryAfter ?? 0)
        }
    }
}
